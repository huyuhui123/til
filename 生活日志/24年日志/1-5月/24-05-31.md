今天学习到了一点tts语音合成的模型使用，不过我还是对如何训练出这一模型感兴趣，在tts领域里，想要做到输出的语音无限接近于人类语音，肯定需要打好文字标签的语音来给模型进行训练


目的
文字语音合成

动手
pip 安装
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/ omegaconf


代码示例
加载模型
推断
加参数
抽样随机扬声器
两级控制
LLM Call

视频
中英文
验证中英文朗读有没有问题
语码转换
验证中英文穿插有没有奇怪
细节控制
朗读语气词编入
说话人生成
需要语音生成说话人，然后文字转语音
对话优化
lora微调


我怎么换对话人，或者，我怎么生成一个对话人呢？
通过找音色来找一个好听的声音
可能要自己写训练的

为什么ChatTTS会用到这么多模型？

这个语音合成有很多模型
vocos
声码器 https://github.com/gemelo-ai/voco
其作用是将模型生成的声学特征（通常是频谱表示）转换为真实的声音信号（也就是最后一步）
dvae
编码器 用于学习声音特征的表示，比如说话人的身份、语速、情感
gpt
生成式预训练变换器。GPT 是一种基于 Transformer 架构的神经网络模型，用于生成文本数据。在tts中用于处理文本数据
decoder
解码器 负责将文本转换为声学特征


tokenizer
是一个将文本数据转换为模型可接受的输入形式的工具。通常用于将原始文本数据分割成单词或者子词，并将其转换为模型可以处理的向量表示形式。
spk_stat
这个名词可能指的是说话者统计信息（Speaker Statistics），用于描述说话者的声音特征或者语音样本的一些统计属性
可能用于训练模型时提供额外的说话者信息，以便更好地进行语音合成。

自回归任务
后面生成的数据都和前面有关


这里说了合成语音需要用到这些模型，但没有说训练模型时是怎么训练的
这么多模型，都需要专门训练，比如vocos，就需要专门训练如何把频谱转化成真实的声音信号
dvae就需要学习声音特征的标识
gpt需要

如何让机器生成更真实的语音，也就是在文字中通过在样本训练学习到的声音特征，从而达到理解文字的能力

想要实现文字转语音，想要让机器生成的语音更加真实，就需要很多真实的数据来供模型学习，

所以首先第一层输入数据是音频，机器不能识别音频所以要先转成文字，并把音频与文字绑定在一起，让机器自己根据文字来制作音频，然后和原音频做对比，从而判断机器生成的音频的准确度


音频数据+对应文本数据样本 数据处理：语音转文字、分词（tokenizer）
->

文本预处理
tokenizer 分词
gpt

decoder 文本转声学特征

dvae 学习语音中的特征表示，去影响vocos、decoder

vocos 声学特征转音频

优化器